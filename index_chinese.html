<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>LMC-VUT</title>
    <!--<link href="../../configs/css/mystyle.css" rel="stylesheet">-->
    <link rel="stylesheet" href="./configs/style/jemdoc.css" type="text/css">
    <style type="text/css">
    </style>
</head>
<body style="width:95%;margin-left:auto;margin-right:auto;">

<h1 align="center"; style="font-size:36px; color: #000000; border-bottom: none">视觉理解团队</h1>
<h2 align="center"; style="color: #000000; border-bottom: none">合肥工业大学 (<a href="http://en.hfut.edu.cn/" target="_blank">HFUT</a>)</h2>
<h3 align="center"; style="color: #000000; border-bottom: none">媒体计算实验室 (LMC)</h3>
<h4 align="center"; style="color: #000000; border-bottom: none">访问英文版 [<a href="./index.html" target="_blank">English</a>]</h4>
<hr class="sec_line">

<br>
<div style="text-align:justify; text-align-last:justify; padding-left: 2.0em; padding-right: 2.0em;">
<a href="#introduction"><b>简介</b></a>
<a href="#news"><b>新闻</b></a>
<a href="#researches"><b>研究</b></a>
<a href="#resources"><b>资源</b></a>
<a href="#members"><b>成员</b></a>
<a href="#publications"><b>出版物</b></a>
<a href="#link"><b>链接</b></a>
</div>
<hr style="height:1px; border:none; border-top:1px solid #aaaaaa;">


<h2 id="introduction">简介</h2>
    <p class="textBlock" style="text-align:justify">
        &ensp;&ensp;视觉理解团队致力于通过计算机视觉和自然语言处理技术来理解、生成和转换多媒体内容。 我们致力于手语翻译、图像/视频描述、视觉对话、视频定位和视觉问答等课题的研究，已发表超过15篇国际学术期刊和会议论文，包括IEEE TIP、ACM TOMCCAP、CVPR、AAAI、IJCAI、ACM MM等。
    </p>


<h2 id="news">新闻</h2>
    <p>
        <li><i>2020年12月：</i> 一篇论文被AAAI 2021录用。</li>
        <li><i>2020年4月：</i> 一篇论文被IJCAI 2020录用。</li>
        <li><i>2020年2月：</i> 一篇论文被CVPR 2020录用。</li>
    </p>


<h2 id="researches">研究</h2>
    <table border="0" width="100%">
        <tbody>
            <tr>
                <th width="30%"></th>
                <th width="70%"></th>
            <tr>
                <td>
                    <div align="left">
                        <a href="./researches/SLT/slt.html">
                        <img src="./researches/SLT/overview.png" alt="" class="img_overview">
                        </a>
                    </div>
                </td>
                <td valign="baseline">
                    <b><a href="./researches/SLT/slt.html">手语翻译</a></b><br>
                    <p class="textBlock" style="text-align:justify">
                        &ensp;&ensp;本部分涵盖与手语识别相关的研究，主要是连续手语翻译（CSLT）。 为了提高离散手语词的识别准确性，一些早期的工作设计了一种自适应隐马尔可夫模型（HMM）框架。 这些方法可以充分探索隐藏手语状态之间的内在属性和互补关系。 CSLT面临着混合语义学习带来的挑战，其中包括视觉表示、手语语言学和文本语法的顺序变化······ [<a href="./researches/SLT/slt.html" target="_blank">详细</a>]
                    </p>
                </td>
            </tr> 
            <tr>
                <td>
                    <div align="left">
                        <a href="./researches/image_analysis/slt.html">
                        <img src="./researches/image_analysis/overview.png" alt="" class="img_overview">
                        </a>
                    </div>
                </td>
                <td valign="baseline">
                    <b><a href="./researches/image_analysis/slt.html">图像分析</a></b><br>
                    <p class="textBlock" style="text-align:justify">
                        &ensp;&ensp;等待更新中······ [<a href="./researches/SLT/slt.html" target="_blank">详细</a>]
                    </p>
                </td>
            </tr> 
            <tr>
                <td>
                    <div align="left">
                        <a href="./researches/video_understanding/slt.html">
                        <img src="./researches/video_understanding/overview.png" alt="" class="img_overview">
                        </a>
                    </div>
                </td>
                <td valign="baseline">
                    <b><a href="./researches/video_understanding/slt.html">视频理解</a></b><br>
                    <p class="textBlock" style="text-align:justify">
                        &ensp;&ensp;等待更新中······ [<a href="./researches/SLT/slt.html" target="_blank">详细</a>]
                    </p>
                </td>
            </tr> 
        </tbody>
    </table>


<h2 id="resources">资源</h2>
    <p class="textBlock">
        等待更新中······
    </p>


<h2 id="members">成员</h2>
    <h3>教师</h3>
        <table border="0" width="100%">
            <tbody>
                <tr>
                    <th width="15%">状态</th>
                    <th width="15%">姓名</th>
                    <th width="25%">联系方式</th>
                    <th width="45%">研究方向</th>
                </tr>
                <tr>
                    <td>教授</td>
                    <td><a href="http://ci.hfut.edu.cn/2020/1209/c11504a245810/page.htm", target="_blank">郭丹</a></td>
                    <td>guodan&#64hfut.edu.cn</td>
                    <td>机器视觉、机器学习、深度学习、模式识别</td>
                </tr>
            </tbody>
        </table>

    <h3>学生</h3>
        <table border="0" width="100%">
            <tbody>
                <tr>
                    <th width="15%">状态</th>
                    <th width="15%">姓名</th>
                    <th width="25%">联系方式</th>
                    <th width="45%">研究方向</th>
                    <!--<th width="50px">Remark</th> -->
                </tr>
                <tr align="left"><td>博士研究生</td><td>宋培培</td><td>beta.songpp&#64gmail.com</td><td>图像/视频描述</td></tr>
                <tr align="left"><td>博士研究生</td><td><a href="https://tangshengeng.github.io/", target="_blank">唐申庚</a></td><td>tsg1995&#64mail.hfut.edu.cn</td><td>连续手语翻译</td></tr>
                <tr align="left"><td>博士研究生</td><td>李坤</td><td>kunli.hfut&#64gmail.com</td><td>视频定位、人群计数</td></tr>
                <tr align="left"><td>博士研究生</td><td>王辉</td><td>wanghui.hfut&#64gmail.com</td><td>视觉对话、视频问答</td></tr>
                <tr align="left"><td>博士研究生</td><td>周金星</td><td>--</td><td>音视频事件定位</td></tr>
                <tr align="left"><td>硕士研究生</td><td>桂毓灵</td><td>aislinggui&#64gmail.com</td><td>--</td></tr>
                <tr align="left"><td>硕士研究生</td><td>严士涵</td><td>--</td><td>--</td></tr>
                <tr align="left"><td>硕士研究生</td><td>朋帆</td><td>--</td><td>--</td></tr>
                <tr align="left"><td>硕士研究生</td><td>张静</td><td>--</td><td>图像描述</td></tr>
                <tr align="left"><td>硕士研究生</td><td>姚沈涛</td><td>--</td><td>视频问答</td></tr>
                <tr align="left"><td>硕士研究生</td><td>卢天一</td><td>--</td><td>图像描述</td></tr>
                <tr align="left"><td>硕士研究生</td><td><a href="https://mrycguo.github.io/", target="_blank">郭义臣</td><td>guoyichen&#64mail.hfut.edu.cn</td><td>Video Grouding</td></tr>
                <tr align="left"><td>硕士研究生</td><td>周晟</td><td>--</td><td>--</td></tr>
            </tbody>
        </table>


<h2 id="publications">出版物</h2>
    <p class="textBlock">
        <b>会议论文：</b>
        <ol>
            <li>Kun Li, Dan Guo, and Meng Wang, "Proposal-Free Video Grounding with Contextual Pyramid Network", <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2021.</li>
            <li>Dan Guo, Yang Wang, Peipei Song, and Meng Wang, "Recurrent Relational Memory Network for Unsupervised Image Captioning", <i>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</i>, 2020.
                [<a href="https://www.ijcai.org/Proceedings/2020/0128", target="_blank">Link</a>][<a href="https://", target="_blank">PDF</a>][<a href="https://", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Hui Wang, Hanwang Zhang, Zhengjun Zha, and Meng Wang, "Iterative Context-Aware Graph Inference for Visual Dialog", <i>Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2020.</li>
            <li>Yuling Gui, Dan Guo, and Ye Zhao, "Semantic Enhanced Encoder-Decoder Network (SEN) for Video Captioning", <i>Workshop on Multimedia for Accessible Human Computer Interfaces (<strong>MAHCI</strong>)</i>, 2019.</li>
            <li>Xiankun Pei, Dan Guo, and Ye Zhao, "Continuous Sign Language Recognition Based on Pseudo-supervised Learning", <i>Workshop on Multimedia for Accessible Human Computer Interfaces (<strong>MAHCI</strong>)</i>, 2019.</li>
            <li>Peipei Song, Dan Guo, Haoran Xin, and Meng Wang, "Parallel Temporal Encoder For Sign Language Translation", <i>IEEE International Conference on Image Processing (<strong>ICIP</strong>)</i>, 2019.
                [<a href="https://ieeexplore.ieee.org/abstract/document/8803123", target="_blank">Link</a>][<a href="./publications/ICIP2019PTE/paper.pdf", target="_blank">PDF</a>][<a href="./publications/ICIP2019PTE/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Kun Li, and Meng Wang, "DADNet：Dilated-Attention-Deformable ConvNet for Crowd Counting", <i>ACM International Conference on Multimedia (<strong>ACM MM</strong>)</i>, 2019.</li>
            <li>Dan Guo, Shengeng Tang,and Meng Wang, "Connectionist Temporal Modeling of Video and Language：A Joint Model for Translation and Sign Labeling", <i>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</i>, 2019.
                [<a href="https://www.ijcai.org/Proceedings/2019/106", target="_blank">Link</a>][<a href="./publications/IJCAI2019CTM/paper.pdf", target="_blank">PDF</a>][<a href="./publications/IJCAI2019CTM/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Shuo Wang, Qi Tian, and Meng Wang, "Dense Temporal Convolution Network for Sign Language Translation", <i>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</i>, 2019.
                [<a href="https://www.ijcai.org/Proceedings/2019/105", target="_blank">Link</a>][<a href="./publications/IJCAI2019DenseTCN/paper.pdf", target="_blank">PDF</a>][<a href="./publications/IJCAI2019DenseTCN/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Hui Wang, and Meng Wang, "Dual Visual Attention Network for Visual Dialog", <i>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</i>, 2019.</li>
            <li>Shuo Wang, Dan Guo, Wengang Zhou, Zhengjun Zha, and Meng Wang, "Connectionist Temporal Fusion for Sign Language Translation", <i>International ACM International Conference on Multimedia (<strong>ACM MM</strong>)</i>, 2018.
                [<a href="https://dl.acm.org/doi/10.1145/3240508.3240671", target="_blank">Link</a>][<a href="./publications/ACMMM2018CTF/paper.pdf", target="_blank">PDF</a>][<a href="./publications/ACMMM2018CTF/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Wengang Zhou, Houqiang Li, and Meng Wang, "Hierarchical LSTM for Sign Language Translation", <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2018.
                [<a href="https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16177", target="_blank">Link</a>][<a href="./publications/AAAI2018HLSTM/paper.pdf", target="_blank">PDF</a>][<a href="./publications/AAAI2018HLSTM/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Wengang Zhou, Houqiang Li, and Meng Wang, "Sign Language Recognition Based on Adaptive HMMs with Data Augmentation", <i>IEEE International Conference on Image Processing (<strong>ICIP</strong>)</i>, 2016.
                [<a href="https://ieeexplore.ieee.org/document/7532885", target="_blank">Link</a>][<a href="./publications/ICIP2016AHMM/paper.pdf", target="_blank">PDF</a>][<a href="./publications/ICIP2016AHMM/bib.html", target="_blank">BibTeX</a>]</li>
        </ol>
    </p>
    <p class="textBlock">
        <b>期刊论文：</b>
        <ol>
            <li>Dan Guo, Hui Wang, Shuhui Wang, and Meng Wang, "Textual-Visual Reference-Aware Attention Network for Visual Dialog", <i>IEEE Transactions on Image Processing (<strong>TIP</strong>)</i>, 2020.</li>
            <li>Dan Guo, Wengang Zhou, Anyang Li, Houqiang Li, and Meng Wang, "Hierarchical Recurrent Deep Fusion Using Adaptive Clip Summarization for Sign Language Translation", <i>IEEE Transactions on Image Processing (<strong>TIP</strong>)</i>, 2020.
                [<a href="https://ieeexplore.ieee.org/document/8846585", target="_blank">Link</a>][<a href="./publications/TIP2020HRF/paper.pdf", target="_blank">PDF</a>][<a href="./publications/TIP2020HRF/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Shuo Wang, Dan Guo, Xin Xu, Li Zhuo, and Meng Wang, "Cross-Modality Retrieval by Joint Correlation Learning", <i>ACM Transactions on Multimedia Computing Communications and Applications (<strong>TOMCCAP</strong>)</i>, 2019.
                [<a href="https://dl.acm.org/doi/10.1145/3314577", target="_blank">Link</a>][<a href="./publications/", target="_blank">PDF</a>][<a href="./publications/", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Wengang Zhou, Houqiang Li, and Meng Wang, "Online Early-Late Fusion Based on Adaptive HMM for Sign Language Recognition", <i>ACM Transactions on Multimedia Computing Communications and Applications (<strong>TOMCCAP</strong>)</i>, 2018.
                [<a href="https://dl.acm.org/doi/10.1145/3152121", target="_blank">Link</a>][<a href="./publications/TOMCCAP2018OELF/paper.pdf", target="_blank">PDF</a>][<a href="./publications/TOMCCAP2018OELF/bib.html", target="_blank">BibTeX</a>]</li>
            <li>郭丹, 唐申庚, 洪日昌, 汪萌, "手语识别、翻译与生成综述", <i>计算机科学</i>, 2021.[<a href="http://www.jsjkx.com/CN/10.11896/jsjkx.210100227", target="_blank">Link</a>][<a href="./publications/JSJKX2021Review/paper.pdf", target="_blank">PDF</a>][<a href="./publications/JSJKX2021Review/bib.html", target="_blank">BibTeX</a>]</li>
            <li>熊成鑫, 郭丹, 刘学亮, "时域候选优化的时序动作检测", <i>中国图象图形学报</i>, 2020.[<a href="http://www.cjig.cn/html/jig/2020/7/20200713.htm", target="_blank">Link</a>]</li>
        </ol>   
    </p>


<h2 id="链接">Link &nbsp<a href="#home" style="color:#666; font-size:15px;"></a></h2>
  <ul>
    <li><a href="https://tangshengeng.github.io/CCF/" target="_blank">CCF会议</a>：CCF推荐的国际学术会议信息更新。</li>
    <li><a href="https://blog.csdn.net/m0_37369043/article/details/102926076" target="_blank">会议链接</a>：机器学习与人工智能领域国际学术会议链接（网站、论文）</li>
    <li><a href="./source/gpu_resources.html" target="_blank">GPU资源</a>：校内访问GPU资源</li>
  </ul>

<!-- <h2 align="center" style="border-bottom: none"><a href="../../index.html"><b>[Back to Homepage]</b></a></h2> -->
<hr style="height:1px;border:none;border-top:1px solid #555555;">
<div align="right" style="font-family:verdana;color:#800000">&copy; 唐申庚 2021 &nbsp&nbsp&nbsp&nbsp&nbsp 最近更新时间：2021年3月27日</div>

</body>
</html>
