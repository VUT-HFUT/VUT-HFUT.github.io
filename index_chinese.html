<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>LMC-VUT</title>
    <!--<link href="../../configs/css/mystyle.css" rel="stylesheet">-->
    <link rel="stylesheet" href="./configs/style/jemdoc.css" type="text/css">
    <style type="text/css">
    </style>
</head>
<body style="width:95%;margin-left:auto;margin-right:auto;">

<h1 align="center"; style="font-size:36px; color: #000000; border-bottom: none">视觉理解团队</h1>
<h2 align="center"; style="color: #000000; border-bottom: none">合肥工业大学 (<a href="http://en.hfut.edu.cn/" target="_blank">HFUT</a>)</h2>
<h3 align="center"; style="color: #000000; border-bottom: none">媒体计算实验室 (LMC)</h3>
<h4 align="center"; style="color: #000000; border-bottom: none">访问英文版 [<a href="./index.html" target="_blank">English</a>]</h4>
<hr class="sec_line">

<br>
<div style="text-align:justify; text-align-last:justify; padding-left: 2.0em; padding-right: 2.0em;">
<a href="#introduction"><b>简介</b></a>
<a href="#news"><b>新闻</b></a>
<a href="#researches"><b>研究</b></a>
<a href="#members"><b>成员</b></a>
<a href="#publications"><b>出版物</b></a>
<a href="#resources"><b>资源</b></a>
<a href="#link"><b>链接</b></a>
</div>
<hr style="height:1px; border:none; border-top:1px solid #aaaaaa;">


<h2 id="introduction">简介</h2>
    <p class="textBlock" style="text-align:justify">
        &ensp;&ensp;视觉理解团队致力于通过计算机视觉和自然语言处理技术来理解、生成和转换多媒体内容。 我们致力于手语翻译、图像/视频描述、视觉对话、视频定位和视觉问答等课题的研究，已发表超过20篇国际学术期刊和会议论文，包括IEEE TPAMI、IEEE TIP、IEEE TMM、ACM TOMCCAP、CVPR、AAAI、IJCAI、ACM MM等。
    </p>


<h2 id="news">新闻</h2>
    <p>
        <li><i>2021年8月：</i> 一篇论文被ACM MM 2021录用。</li>
        <li><i>2020年12月：</i> 一篇论文被AAAI 2021录用。</li>
        <li><i>2020年4月：</i> 一篇论文被IJCAI 2020录用。</li>
        <li><i>2020年2月：</i> 一篇论文被CVPR 2020录用。</li>
    </p>


<h2 id="researches">研究</h2>
    <table border="0" width="100%">
        <tbody>
            <tr>
                <th width="30%"></th>
                <th width="70%"></th>
            <tr>
                <td>
                    <div align="left">
                        <a href="./researches/SLT/slt.html">
                        <img src="./researches/SLT/overview.png" alt="" class="img_overview">
                        </a>
                    </div>
                </td>
                <td valign="baseline">
                    <b><a href="./researches/SLT/slt.html">手语翻译与生成</a></b><br>
                    <p class="textBlock" style="text-align:justify">
                        &ensp;&ensp;本部分涵盖与手语识别相关的研究，主要是连续手语翻译（CSLT）。 为了提高离散手语词的识别准确性，一些早期的工作设计了一种自适应隐马尔可夫模型（HMM）框架。 这些方法可以充分探索隐藏手语状态之间的内在属性和互补关系。 CSLT面临着混合语义学习带来的挑战，其中包括视觉表示、手语语言学和文本语法的顺序变化······ [<a href="./researches/SLT/slt.html" target="_blank">详细</a>]
                    </p>
                </td>
            </tr> 
            <tr>
                <td>
                    <div align="left">
                        <a href="./researches/VQA_VisualDialog/VQA_VisualDialog.html">
                        <img src="./researches/VQA_VisualDialog/overview.png" alt="" class="img_overview">
                        </a>
                    </div>
                </td>
                <td valign="baseline">
                    <b><a href="./researches/VQA_VisualDialog/VQA_VisualDialog.html">视觉问答与对话</a></b><br>
                    <p class="textBlock" style="text-align:justify">
                        &ensp;&ensp;本部分涵盖与跨媒体视觉推理相关的研究，主要包括基于图像/视频的问答和对话生成。 [<a href="./researches/VQA_VisualDialog/VQA_VisualDialog.html" target="_blank">Details</a>]
                    </p>
                </td>
            </tr>             
            
            <tr>
                <td>
                    <div align="left">
                        <a href="./researches/Caption/caption.html">
                        <img src="./researches/Caption/overview.png" alt="" class="img_overview">
                        </a>
                    </div>
                </td>
                <td valign="baseline">
                    <b><a href="./researches/Caption/caption.html">视觉描述生成</a></b><br>
                    <p class="textBlock" style="text-align:justify">
                        &ensp;&ensp;本部分涵盖与视觉描述生成相关的研究，主要是指根据图像/视频的内容自动生成文本的描述，最新的工作包括跨语言的视觉字幕生成和情感视频描述等。 [<a href="./researches/Caption/caption.html" target="_blank">Details</a>]
                    </p>
                </td>
            </tr> 
            
            <tr>
                <td>
                    <div align="left">
                        <a href="./researches/video_understanding/video.html">
                        <img src="./researches/video_understanding/overview.jpg" alt="" class="img_overview">
                        </a>
                    </div>
                </td>
                <td valign="baseline">
                    <b><a href="./researches/video_understanding/video.html">视觉理解与分析</a></b><br>
                    <p class="textBlock" style="text-align:justify">
                        &ensp;&ensp;本部分涵盖与视觉内容理解相关的研究，包括基于图像的人群基数、基于图像的视觉对象定位、文本引导下的视频动作定位等。 [<a href="./researches/SLT/slt.html" target="_blank">Details</a>]
                    </p>
                </td>
            </tr> 
        </tbody>
    </table>
    

<h2 id="members">成员</h2>
    <h3>教师</h3>
        <table border="0" width="100%">
            <tbody>
                <tr>
                    <th width="15%">状态</th>
                    <th width="15%">姓名</th>
                    <th width="25%">联系方式</th>
                    <th width="45%">研究方向</th>
                </tr>
                <tr>
                    <td>教授</td>
                    <td><a href="http://ci.hfut.edu.cn/2020/1209/c11504a245810/page.htm", target="_blank">郭丹</a></td>
                    <td>guodan&#64hfut.edu.cn</td>
                    <td>机器视觉、机器学习、深度学习、模式识别</td>
                </tr>
            </tbody>
        </table>

    <h3>学生</h3>
        <table border="0" width="100%">
            <tbody>
                <tr>
                    <th width="15%">状态</th>
                    <th width="15%">姓名</th>
                    <th width="25%">联系方式</th>
                    <th width="45%">研究方向</th>
                    <!--<th width="50px">Remark</th> -->
                </tr>
                <tr align="left"><td>博士研究生</td><td><a href="https://songpipi.github.io/", target="_blank">宋培培</a></td><td>beta.songpp&#64gmail.com</td><td>图像/视频描述</td></tr>
                <tr align="left"><td>博士研究生</td><td><a href="https://tangshengeng.github.io/", target="_blank">唐申庚</a></td><td>tsg1995&#64mail.hfut.edu.cn</td><td>手语翻译与生成</td></tr>
                <tr align="left"><td>博士研究生</td><td><a href="https://kunli-cs.github.io/", target="_blank">李坤</a></td><td>kunli.hfut&#64gmail.com</td><td>视觉定位、人群计数</td></tr>
                <tr align="left"><td>博士研究生</td><td>王辉</td><td>wanghui.hfut&#64gmail.com</td><td>视觉对话、视频问答</td></tr>
                <tr align="left"><td>博士研究生</td><td>周金星</td><td>--</td><td>音视频事件定位</td></tr>
                <tr align="left"><td>博士研究生</td><td>李琦</td><td>--</td><td>心率估计</td></tr>
                <tr align="left"><td>硕士研究生</td><td>张静</td><td>--</td><td>图像描述</td></tr>
                <tr align="left"><td>硕士研究生</td><td>姚沈涛</td><td>--</td><td>视频问答</td></tr>
                <tr align="left"><td>硕士研究生</td><td>卢天一</td><td>--</td><td>图像描述</td></tr>
                <tr align="left"><td>硕士研究生</td><td><a href="https://mrycguo.github.io/", target="_blank">郭义臣</td><td>mrycguo&#64gmail.com</td><td>视频定位</td></tr>
                <tr align="left"><td>硕士研究生</td><td>周晟</td><td>--</td><td>文本视觉对话</td></tr>
                <tr align="left"><td>硕士研究生</td><td>钱威</td><td>--</td><td>心率估计</td></tr>
                <tr align="left"><td>硕士研究生</td><td>张研</td><td>--</td><td>--</td></tr>
                <tr align="left"><td>硕士研究生</td><td>王飞</td><td>--</td><td>--</td></tr>
                <tr align="left"><td>硕士研究生</td><td>郑振涛</td><td>--</td><td>--</td></tr>
            </tbody>
        </table>
    
    <h3>毕业生</h3>
        <table border="0" width="100%">
            <tbody>
                <tr>
                    <th width="15%">Status</th>
                    <th width="15%">Name</th>
                    <th width="70%">Now</th>
                    <!--<th width="50px">Remark</th> -->
                </tr>
                <tr align="left"><td>Msc. 2020</td><td>熊成鑫</td><td>--</td></tr>
                <tr align="left"><td>Msc. 2020</td><td>裴现坤</td><td>上海浦发银行</td></tr>
                <tr align="left"><td>Msc. 2021</td><td>严士涵</td><td>徽商银行</td></tr>
                <tr align="left"><td>Msc. 2021</td><td>桂毓灵</td><td>--</td></tr>
                <tr align="left"><td>Msc. 2021</td><td>朋帆</td><td>--</td></tr>
            </tbody>
        </table>


<h2 id="publications">出版物</h2>
    <p class="textBlock">
        <b>会议论文：</b>
        <ol>
            <li>Hui Wang, Dan Guo, Xiansheng Hua, and Meng Wang, "Pairwise VLAD Interaction Network for Video Question Answering", <i>ACM International Conference on Multimedia (<strong>ACM MM</strong>)</i>, 2021.</li>
            <li>Kun Li, Dan Guo, and Meng Wang, "Proposal-Free Video Grounding with Contextual Pyramid Network", <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2021.</li>
            <li>Dan Guo, Yang Wang, Peipei Song, and Meng Wang, "Recurrent Relational Memory Network for Unsupervised Image Captioning", <i>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</i>, 2020.
                [<a href="https://www.ijcai.org/Proceedings/2020/0128", target="_blank">Link</a>][<a href="https://", target="_blank">PDF</a>][<a href="https://", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Hui Wang, Hanwang Zhang, Zhengjun Zha, and Meng Wang, "Iterative Context-Aware Graph Inference for Visual Dialog", <i>Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2020.</li>
            <li>Fan Peng, Kun Li, Xueliang Liu, and Dan Guo, "AOPNet: Anchor Offset Prediction Network for Temporal Action Proposal Generation", <i>International Conference on Signal Processing, Communications and Computing (<strong>ICSPCC</strong>)</i>, 2020.</li>
            <li>Yuling Gui, Dan Guo, and Ye Zhao, "Semantic Enhanced Encoder-Decoder Network (SEN) for Video Captioning", <i>Workshop on Multimedia for Accessible Human Computer Interfaces (<strong>MAHCI</strong>)</i>, 2019.</li>
            <li>Xiankun Pei, Dan Guo, and Ye Zhao, "Continuous Sign Language Recognition Based on Pseudo-supervised Learning", <i>Workshop on Multimedia for Accessible Human Computer Interfaces (<strong>MAHCI</strong>)</i>, 2019.</li>
            <li>Peipei Song, Dan Guo, Haoran Xin, and Meng Wang, "Parallel Temporal Encoder For Sign Language Translation", <i>IEEE International Conference on Image Processing (<strong>ICIP</strong>)</i>, 2019.
                [<a href="https://ieeexplore.ieee.org/abstract/document/8803123", target="_blank">Link</a>][<a href="./publications/ICIP2019PTE/paper.pdf", target="_blank">PDF</a>][<a href="./publications/ICIP2019PTE/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Kun Li, and Meng Wang, "DADNet：Dilated-Attention-Deformable ConvNet for Crowd Counting", <i>ACM International Conference on Multimedia (<strong>ACM MM</strong>)</i>, 2019.</li>
            <li>Dan Guo, Shengeng Tang,and Meng Wang, "Connectionist Temporal Modeling of Video and Language：A Joint Model for Translation and Sign Labeling", <i>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</i>, 2019.
                [<a href="https://www.ijcai.org/Proceedings/2019/106", target="_blank">Link</a>][<a href="./publications/IJCAI2019CTM/paper.pdf", target="_blank">PDF</a>][<a href="./publications/IJCAI2019CTM/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Shuo Wang, Qi Tian, and Meng Wang, "Dense Temporal Convolution Network for Sign Language Translation", <i>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</i>, 2019.
                [<a href="https://www.ijcai.org/Proceedings/2019/105", target="_blank">Link</a>][<a href="./publications/IJCAI2019DenseTCN/paper.pdf", target="_blank">PDF</a>][<a href="./publications/IJCAI2019DenseTCN/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Hui Wang, and Meng Wang, "Dual Visual Attention Network for Visual Dialog", <i>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</i>, 2019.</li>
            <li>Shuo Wang, Dan Guo, Wengang Zhou, Zhengjun Zha, and Meng Wang, "Connectionist Temporal Fusion for Sign Language Translation", <i>International ACM International Conference on Multimedia (<strong>ACM MM</strong>)</i>, 2018.
                [<a href="https://dl.acm.org/doi/10.1145/3240508.3240671", target="_blank">Link</a>][<a href="./publications/ACMMM2018CTF/paper.pdf", target="_blank">PDF</a>][<a href="./publications/ACMMM2018CTF/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Wengang Zhou, Houqiang Li, and Meng Wang, "Hierarchical LSTM for Sign Language Translation", <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2018.
                [<a href="https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16177", target="_blank">Link</a>][<a href="./publications/AAAI2018HLSTM/paper.pdf", target="_blank">PDF</a>][<a href="./publications/AAAI2018HLSTM/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Wengang Zhou, Houqiang Li, and Meng Wang, "Sign Language Recognition Based on Adaptive HMMs with Data Augmentation", <i>IEEE International Conference on Image Processing (<strong>ICIP</strong>)</i>, 2016.
                [<a href="https://ieeexplore.ieee.org/document/7532885", target="_blank">Link</a>][<a href="./publications/ICIP2016AHMM/paper.pdf", target="_blank">PDF</a>][<a href="./publications/ICIP2016AHMM/bib.html", target="_blank">BibTeX</a>]</li>
        </ol>
    </p>
    <p class="textBlock">
        <b>期刊论文：</b>
        <ol>
            <li>Dan Guo, Hui Wang, and Meng Wang, "Context-Aware Graph Inference with Knowledge Distillation for Visual Dialog", <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</i>, 2021.[<a href="https://ieeexplore.ieee.org/document/9444809", target="_blank">Link</a>]</li>
            <li>Shengeng Tang, Dan Guo, Richang Hong, and Meng Wang, "Graph-Based Multimodal Sequential Embedding for Sign Language Translation", <i>IEEE Transactions on Multimedia (<strong>TMM</strong>)</i>, 2021.[<a href="https://ieeexplore.ieee.org/document/9556136", target="_blank">Link</a>][<a href="./publications/TMM2021MSeqGraph/paper.pdf", target="_blank">PDF</a>][<a href="./publications/TMM2021MSeqGraph/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Hui Wang, Shuhui Wang, and Meng Wang, "Textual-Visual Reference-Aware Attention Network for Visual Dialog", <i>IEEE Transactions on Image Processing (<strong>TIP</strong>)</i>, 2020.</li>
            <li>Dan Guo, Wengang Zhou, Anyang Li, Houqiang Li, and Meng Wang, "Hierarchical Recurrent Deep Fusion Using Adaptive Clip Summarization for Sign Language Translation", <i>IEEE Transactions on Image Processing (<strong>TIP</strong>)</i>, 2020.
                [<a href="https://ieeexplore.ieee.org/document/8846585", target="_blank">Link</a>][<a href="./publications/TIP2020HRF/paper.pdf", target="_blank">PDF</a>][<a href="./publications/TIP2020HRF/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Shuo Wang, Dan Guo, Xin Xu, Li Zhuo, and Meng Wang, "Cross-Modality Retrieval by Joint Correlation Learning", <i>ACM Transactions on Multimedia Computing Communications and Applications (<strong>TOMCCAP</strong>)</i>, 2019.
                [<a href="https://dl.acm.org/doi/10.1145/3314577", target="_blank">Link</a>][<a href="./publications/", target="_blank">PDF</a>][<a href="./publications/", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Wengang Zhou, Houqiang Li, and Meng Wang, "Online Early-Late Fusion Based on Adaptive HMM for Sign Language Recognition", <i>ACM Transactions on Multimedia Computing Communications and Applications (<strong>TOMCCAP</strong>)</i>, 2018.
                [<a href="https://dl.acm.org/doi/10.1145/3152121", target="_blank">Link</a>][<a href="./publications/TOMCCAP2018OELF/paper.pdf", target="_blank">PDF</a>][<a href="./publications/TOMCCAP2018OELF/bib.html", target="_blank">BibTeX</a>]</li>
            <li>郭丹, 唐申庚, 洪日昌, 汪萌, "手语识别、翻译与生成综述", <i>计算机科学</i>, 2021.[<a href="http://www.jsjkx.com/CN/10.11896/jsjkx.210100227", target="_blank">Link</a>][<a href="./publications/JSJKX2021Review/paper.pdf", target="_blank">PDF</a>][<a href="./publications/JSJKX2021Review/bib.html", target="_blank">BibTeX</a>]</li>
            <li>熊成鑫, 郭丹, 刘学亮, "时域候选优化的时序动作检测", <i>中国图象图形学报</i>, 2020.[<a href="http://www.cjig.cn/html/jig/2020/7/20200713.htm", target="_blank">Link</a>]</li>
            <li>鲁志红, 郭丹, 汪萌, "基于加权运动估计和矢量分割的运动补偿内插算法", <i>自动化学报</i>, 2015.[<a href="http://aas.net.cn/article/id/18677", target="_blank">Link</a>]</li>
        </ol>   
    </p>
    <p class="textBlock">
        <b>授权专利:</b>
        <ol>
            <li>郭丹; 宋培培; 刘祥龙; 汪萌; 基于递归记忆网络的无监督图像描述模型的生成方法, 2022-3-15, 中国, ZL202010049142.2.</li>
            <li>郭丹; 宋培培; 刘祥龙; 汪萌; 基于数据自驱动的多阶特征动态融合手语翻译方法, 2022-3-15, 中国, ZL202010096391.7.</li>
            <li>郭丹; 王辉; 汪萌; 一种基于上下文感知图神经网络的视觉对话生成方法, 2021-6-8, 中国, ZL201910881298.4.</li>
            <li>郭丹; 李坤; 汪萌; 一种基于多尺度注意力机制的人群密度估计方法, 2021-3-9, 中国, ZL201910531606.0.</li>
            <li>郭丹; 王辉; 汪萌; 一种基于上下文感知图神经网络的视觉对话生成方法, 2021-6-8, 中国, ZL201910881298.4.</li>
            <li>郭丹; 宋培培; 赵烨; 汪萌; 基于自适应隐马尔可夫的多特征融合手语识别方法, 2020-07-10, 中国, ZL201811131806.9.</li>
            <li>郭丹; 汪萌; 周文罡; 李厚强; 李传青; 李安阳; 基于非对称多层LSTM的连续手语视频自动翻译方法, 2020-2-11, 中国, ZL201810027551.5.</li>
            <li>郭丹; 王硕; 汪萌; 基于时域卷积网络与循环神经网络融合的手语视频翻译方法, 2019-10-18, 中国, ZL201811070290.1.</li>
            <li>汪萌; 张鹿鸣; 郭丹; 一种基于多任务拓扑学习的航拍图像快速识别系统及其快速识别方法, 2018-2-6, 中国, ZL201510080478.4.</li>
            <li>汪萌; 张鹿鸣; 郭丹; 田绪婷; 一种基于几何重构和语义融合的视点追踪方法, 2017-10-3, 中国, ZL201410733763.7.</li>
            <li>郭丹; 胡学钢; 倪武; 吴信东; 一种基于最大流率路径优先的路网疏散规划方法, 2017-6-6, 中国, ZL201510451828.3.</li>
            <li>汪萌; 杨勋; 洪日昌; 郭丹; 刘奕群; 孙茂松; 一种基于语义映射空间构建的图像检索方法, 2017-5-17, 中国, ZL201410393094.3.</li>
            <li>汪萌; 洪日昌; 李炳南; 刘奕群; 郭丹; 刘学亮; 吴信东; 杨勋; 基于连续数标号子空间学习的检索重排序方法, 2017-2-22, 中国, ZL201410196946.X.</li>
            <li>汪萌; 张鹿鸣; 郭丹; 刘奕群; 孙茂松; 鲁志红; 基于GPS信息视频的三维场景重建方法, 2017-2-22, 中国, ZL201410752454.4.</li>
        </ol>   
    </p>


<h2 id="resources">其他</h2>
    <h3>指导大创项目</h3>
        <table border="0" width="100%">
            <tbody>
                <tr>
                    <th width="15%">立项时间</th>
                    <th width="15%">项目名称</th>
                    <th width="25%">项目层次</th>
                    <th width="45%">项目组成员</th>
                </tr>
                <tr>
                    <td>2022年</td>
                    <td>基于视觉环境感知的视障人士出行导航系统</td>
                    <td>国家级</td>
                    <td>谷纪豪、肖同欢、宋万强、黄滨</td>
                </tr>
                <tr>
                    <td>2022年</td>
                    <td>基于视觉-语言理解的智能室内机器人导航系统</td>
                    <td>省级</td>
                    <td>李家秀、卫天翼、蔡景宜、赵凌霄、费文轩</td>
                </tr>
                <tr>
                    <td>2021年</td>
                    <td>基于多分类目标检测的全自动家居清洗设备</td>
                    <td>校级</td>
                    <td>何梓贻、罗匡、徐梓鑫、倪友炜、马嘉淇</td>
                </tr>
                <tr>
                    <td>2021年</td>
                    <td>基于PyramidBox-Lite模型的口罩识别检测系统</td>
                    <td>校级</td>
                    <td>梁云、付守宇、付泓菁、李跃强、秦崇昀</td>
                </tr>
                <tr>
                    <td>2020年</td>
                    <td>基于人群计数技术的大型超市优化管理系统</td>
                    <td>省级</td>
                    <td>曾纪勇、李泓博、张振兴、银鑫、刘经诚</td>
                </tr>
                <tr>
                    <td>2020年</td>
                    <td>基于场景文字识别的图书检索AI系统</td>
                    <td>校级</td>
                    <td>陈鸿、陈国良、郭志俊、李利艳</td>
                </tr>
                <tr>
                    <td>2019年</td>
                    <td>基于表情识别的课堂质量评判系统</td>
                    <td>校级</td>
                    <td>恽郅、弋绮、万德阳、杨光正奥、马欣</td>
                </tr>
                <tr>
                    <td>2018年</td>
                    <td>“今日食堂”--打造高校智能食堂2.0</td>
                    <td>省级</td>
                    <td>朱航延、王家辉、张方勇、刘志远、李文琪</td>
                </tr>
            </tbody>
        </table>


<h2 id="链接">Link &nbsp<a href="#home" style="color:#666; font-size:15px;"></a></h2>
  <ul>
    <!-- <li><a href="https://tangshengeng.github.io/CCF/" target="_blank">CCF会议</a>：CCF推荐的国际学术会议信息更新。</li> -->
    <li><a href="https://blog.csdn.net/m0_37369043/article/details/102926076" target="_blank">会议链接</a>：机器学习与人工智能领域国际学术会议链接（网站、论文）</li>
    <!-- <li><a href="./source/gpu_resources.html" target="_blank">GPU资源</a>：校内访问GPU资源</li> -->
  </ul>

<!-- <h2 align="center" style="border-bottom: none"><a href="../../index.html"><b>[Back to Homepage]</b></a></h2> -->
<hr style="height:1px;border:none;border-top:1px solid #555555;">
<div align="right" style="font-family:verdana;color:#800000">&copy; 视觉理解团队 2021 &nbsp&nbsp&nbsp&nbsp&nbsp 最近更新时间：2022年4月23日</div>

</body>
</html>
