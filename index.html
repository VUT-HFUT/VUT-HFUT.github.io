<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>LMC-VUT</title>
    <!--<link href="../../configs/css/mystyle.css" rel="stylesheet">-->
    <link rel="stylesheet" href="./configs/style/jemdoc.css" type="text/css">
    <style type="text/css">
    </style>
</head>
<body style="width:95%;margin-left:auto;margin-right:auto;">

<h1 align="center"; style="font-size:36px; color: #000000; border-bottom: none">Visual Understanding Team</h1>
<h2 align="center"; style="color: #000000; border-bottom: none">Hefei University of Technology (<a href="http://en.hfut.edu.cn/" target="_blank">HFUT</a>)</h2>
<h3 align="center"; style="color: #000000; border-bottom: none">Laboratory for Multimedia Computing (LMC)</h3>
<h4 align="center"; style="color: #000000; border-bottom: none">Visit the Chinese Version [<a href="./index_chinese.html" target="_blank">中文</a>]</h4>
<hr class="sec_line">

<br>
<div style="text-align:justify; text-align-last:justify; padding-left: 2.0em; padding-right: 2.0em;">
<a href="#introduction"><b>Introduction</b></a>
<a href="#news"><b>News</b></a>
<a href="#researches"><b>Researches</b></a>
<a href="#resources"><b>Resources</b></a>
<a href="#members"><b>Members</b></a>
<a href="#publications"><b>Publications</b></a>
<a href="#link"><b>Link</b></a>
</div>
<hr style="height:1px; border:none; border-top:1px solid #aaaaaa;">


<h2 id="introduction">Introduction</h2>
    <p class="textBlock" style="text-align:justify">
        &ensp;&ensp;Visual Understanding Team targets on understanding, generating, and transforming multimedia content via computer vision and natural language processing techniques. We are working on sign language translation,  image/video captioning,  visual dialogue, video grouding and VQA. We have published 20+ journal articles and conference papers, including IEEE TPAMI, IEEE TIP, IEEE TMM, ACM TOMCCAP, CVPR, AAAI, IJCAI, ACM MM, etc.
    </p>


<h2 id="news">News</h2>
    <p>
        <li><i>Aug. 2021:</i> One paper is accepted to ACM MM 2021.</li>
        <li><i>Dec. 2020:</i> One paper is accepted to AAAI 2021.</li>
        <li><i>Apr. 2020:</i> One paper is accepted to IJCAI 2020.</li>
        <li><i>Feb. 2020:</i> One paper is accepted to CVPR 2020.</li>
    </p>


<h2 id="researches">Researches</h2>
    <table border="0" width="100%">
        <tbody>
            <tr>
                <th width="30%"></th>
                <th width="70%"></th>
            <tr>
                <td>
                    <div align="left">
                        <a href="./researches/SLT/slt.html">
                        <img src="./researches/SLT/overview.png" alt="" class="img_overview">
                        </a>
                    </div>
                </td>
                <td valign="baseline">
                    <b><a href="./researches/SLT/slt.html">Sign Language Translation</a></b><br>
                    <p class="textBlock" style="text-align:justify">
                        &ensp;&ensp;This part covers the researches related to sign language recognition, which focuses on continuous sign language translation (CSLT). In order to improve the recognition accuracy of isolated sign words, some early works design an adaptive hidden Markov model (HMM) framework. These methods can fully explore the intrinsic properties and complementary relationship among the hidden sign states. CSLT suffers from challenges presented by hybrid semantics learning among sequential variations of visual representations, sign linguistics, and textual grammars... [<a href="./researches/SLT/slt.html" target="_blank">Details</a>]
                    </p>
                </td>
            </tr> 
            
            <tr>
                <td>
                    <div align="left">
                        <a href="./researches/VQA_VisualDialog/VQA_VisualDialog.html">
                        <img src="./researches/VQA_VisualDialog/overview.png" alt="" class="img_overview">
                        </a>
                    </div>
                </td>
                <td valign="baseline">
                    <b><a href="./researches/VQA_VisualDialog/VQA_VisualDialog.html">VQA & Visual Dialog</a></b><br>
                    <p class="textBlock" style="text-align:justify">
                        &ensp;&ensp;This part covers the researches related to VQA and visual dialog. [<a href="./researches/VQA_VisualDialog/VQA_VisualDialog.html" target="_blank">Details</a>]
                    </p>
                </td>
            </tr>             
            
            <tr>
                <td>
                    <div align="left">
                        <a href="./researches/Caption/caption.html">
                        <img src="./researches/Caption/overview.png" alt="" class="img_overview">
                        </a>
                    </div>
                </td>
                <td valign="baseline">
                    <b><a href="./researches/Caption/caption.html">Visual Captioning</a></b><br>
                    <p class="textBlock" style="text-align:justify">
                        &ensp;&ensp;This part covers the researches related to visual captioning, including image captioning and video captioning. [<a href="./researches/Caption/caption.html" target="_blank">Details</a>]
                    </p>
                </td>
            </tr> 
            
            <tr>
                <td>
                    <div align="left">
                        <a href="./researches/video_understanding/video.html">
                        <img src="./researches/video_understanding/overview.jpg" alt="" class="img_overview">
                        </a>
                    </div>
                </td>
                <td valign="baseline">
                    <b><a href="./researches/video_understanding/video.html">Video Understanding</a></b><br>
                    <p class="textBlock" style="text-align:justify">
                        &ensp;&ensp;Waiting for Update... [<a href="./researches/SLT/slt.html" target="_blank">Details</a>]
                    </p>
                </td>
            </tr> 
        </tbody>
    </table>


<h2 id="resources">Resources</h2>
    <p class="textBlock">
        Waiting for Update...
    </p>


<h2 id="members">Members</h2>
    <h3>Teacher</h3>
        <table border="0" width="100%">
            <tbody>
                <tr>
                    <th width="15%">Status</th>
                    <th width="15%">Name</th>
                    <th width="25%">Contact</th>
                    <th width="45%">Research Interest</th>
                </tr>
                <tr>
                    <td>Professor</td>
                    <td><a href="http://ci.hfut.edu.cn/2020/1209/c11504a245810/page.htm", target="_blank">Dan Guo</a></td>
                    <td>guodan&#64hfut.edu.cn</td>
                    <td>Video Analysis, Pattern Recognition</td>
                </tr>
            </tbody>
        </table>

    <h3>Student</h3>
        <table border="0" width="100%">
            <tbody>
                <tr>
                    <th width="15%">Status</th>
                    <th width="15%">Name</th>
                    <th width="25%">Contact</th>
                    <th width="45%">Research Interest</th>
                    <!--<th width="50px">Remark</th> -->
                </tr>
                <tr align="left"><td>Ph.D student</td><td><a href="https://songpipi.github.io/", target="_blank">Peipei Song</a></td><td>beta.songpp&#64gmail.com</td><td>Image Captioning, Video Captioning</td></tr>
                <tr align="left"><td>Ph.D student</td><td><a href="https://tangshengeng.github.io/", target="_blank">Shengeng Tang</a></td><td>tsg1995&#64mail.hfut.edu.cn</td><td>Sign Language Translation & Production</td></tr>
                <tr align="left"><td>Ph.D student</td><td><a href="https://kunli-cs.github.io/", target="_blank">Kun Li</a></td><td>kunli.hfut&#64gmail.com</td><td>Video Grouding, Crowd Counting</td></tr>
                <tr align="left"><td>Ph.D student</td><td>Hui Wang</td><td>wanghui.hfut&#64gmail.com</td><td>Visual Dialogue, Video Question Answering</td></tr>
                <tr align="left"><td>Ph.D student</td><td>Jinxing Zhou</td><td>--</td><td>Audio-Visual Event Localization</td></tr>
                <tr align="left"><td>Ph.D student</td><td>Qi Li</td><td>--</td><td>Heart Rate Measurement</td></tr>
                <tr align="left"><td>Master student</td><td>Jing Zhang</td><td>--</td><td>Image Captioning</td></tr>
                <tr align="left"><td>Master student</td><td>Shentao Yao</td><td>--</td><td>Video Question Answering</td></tr>
                <tr align="left"><td>Master student</td><td>Tianyi Lu</td><td>--</td><td>Image Captioning</td></tr>
                <tr align="left"><td>Master student</td><td><a href="https://mrycguo.github.io/", target="_blank">Yichen Guo</td><td>mrycguo&#64gmail.com</td><td>Video Grouding</td></tr>
                <tr align="left"><td>Master student</td><td>Sheng Zhou</td><td>--</td><td>Text VQA</td></tr>
                <tr align="left"><td>Master student</td><td>Wei Qian</td><td>--</td><td>Heart Rate Measurement</td></tr>
            </tbody>
        </table>
    <h3>Alumni</h3>
        <table border="0" width="100%">
            <tbody>
                <tr>
                    <th width="15%">Status</th>
                    <th width="15%">Name</th>
                    <th width="70%">Now</th>
                    <!--<th width="50px">Remark</th> -->
                </tr>
                <tr align="left"><td>Msc. 2020</td><td>Chengxin Xiong</td><td>--</td></tr>
                <tr align="left"><td>Msc. 2020</td><td>Xiankun Pei</td><td>Shanghai Pudong Development Bank</td></tr>
                <tr align="left"><td>Msc. 2021</td><td>Shihan Yan</td><td>Huishang Bank</td></tr>
                <tr align="left"><td>Msc. 2021</td><td>Yuling Gui</td><td>--</td></tr>
                <tr align="left"><td>Msc. 2021</td><td>Fan Peng</td><td>--</td></tr>
            </tbody>
        </table>


<h2 id="publications">Publications</h2>
    <p class="textBlock">
        <b>Conference papers:</b>
        <ol>
            <li>Hui Wang, Dan Guo, Xiansheng Hua, and Meng Wang, "Pairwise VLAD Interaction Network for Video Question Answering", <i>ACM International Conference on Multimedia (<strong>ACM MM</strong>)</i>, 2021.</li>
            <li>Kun Li, Dan Guo, and Meng Wang, "Proposal-Free Video Grounding with Contextual Pyramid Network", <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2021.</li>
            <li>Dan Guo, Yang Wang, Peipei Song, and Meng Wang, "Recurrent Relational Memory Network for Unsupervised Image Captioning", <i>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</i>, 2020.
                [<a href="https://www.ijcai.org/Proceedings/2020/0128", target="_blank">Link</a>][<a href="https://", target="_blank">PDF</a>][<a href="https://", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Hui Wang, Hanwang Zhang, Zhengjun Zha, and Meng Wang, "Iterative Context-Aware Graph Inference for Visual Dialog", <i>Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2020.</li>
            <li>Fan Peng, Kun Li, Xueliang Liu, and Dan Guo, "AOPNet: Anchor Offset Prediction Network for Temporal Action Proposal Generation", <i>International Conference on Signal Processing, Communications and Computing (<strong>ICSPCC</strong>)</i>, 2020.</li>
            <li>Yuling Gui, Dan Guo, and Ye Zhao, "Semantic Enhanced Encoder-Decoder Network (SEN) for Video Captioning", <i>Workshop on Multimedia for Accessible Human Computer Interfaces (<strong>MAHCI</strong>)</i>, 2019.</li>
            <li>Xiankun Pei, Dan Guo, and Ye Zhao, "Continuous Sign Language Recognition Based on Pseudo-supervised Learning", <i>Workshop on Multimedia for Accessible Human Computer Interfaces (<strong>MAHCI</strong>)</i>, 2019.</li>
            <li>Peipei Song, Dan Guo, Haoran Xin, and Meng Wang, "Parallel Temporal Encoder For Sign Language Translation", <i>IEEE International Conference on Image Processing (<strong>ICIP</strong>)</i>, 2019.
                [<a href="https://ieeexplore.ieee.org/abstract/document/8803123", target="_blank">Link</a>][<a href="./publications/ICIP2019PTE/paper.pdf", target="_blank">PDF</a>][<a href="./publications/ICIP2019PTE/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Kun Li, and Meng Wang, "DADNet：Dilated-Attention-Deformable ConvNet for Crowd Counting", <i>ACM International Conference on Multimedia (<strong>ACM MM</strong>)</i>, 2019.</li>
            <li>Dan Guo, Shengeng Tang,and Meng Wang, "Connectionist Temporal Modeling of Video and Language：A Joint Model for Translation and Sign Labeling", <i>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</i>, 2019.
                [<a href="https://www.ijcai.org/Proceedings/2019/106", target="_blank">Link</a>][<a href="./publications/IJCAI2019CTM/paper.pdf", target="_blank">PDF</a>][<a href="./publications/IJCAI2019CTM/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Shuo Wang, Qi Tian, and Meng Wang, "Dense Temporal Convolution Network for Sign Language Translation", <i>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</i>, 2019.
                [<a href="https://www.ijcai.org/Proceedings/2019/105", target="_blank">Link</a>][<a href="./publications/IJCAI2019DenseTCN/paper.pdf", target="_blank">PDF</a>][<a href="./publications/IJCAI2019DenseTCN/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Hui Wang, and Meng Wang, "Dual Visual Attention Network for Visual Dialog", <i>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</i>, 2019.</li>
            <li>Shuo Wang, Dan Guo, Wengang Zhou, Zhengjun Zha, and Meng Wang, "Connectionist Temporal Fusion for Sign Language Translation", <i>International ACM International Conference on Multimedia (<strong>ACM MM</strong>)</i>, 2018.
                [<a href="https://dl.acm.org/doi/10.1145/3240508.3240671", target="_blank">Link</a>][<a href="./publications/ACMMM2018CTF/paper.pdf", target="_blank">PDF</a>][<a href="./publications/ACMMM2018CTF/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Wengang Zhou, Houqiang Li, and Meng Wang, "Hierarchical LSTM for Sign Language Translation", <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2018.
                [<a href="https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16177", target="_blank">Link</a>][<a href="./publications/AAAI2018HLSTM/paper.pdf", target="_blank">PDF</a>][<a href="./publications/AAAI2018HLSTM/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Wengang Zhou, Houqiang Li, and Meng Wang, "Sign Language Recognition Based on Adaptive HMMs with Data Augmentation", <i>IEEE International Conference on Image Processing (<strong>ICIP</strong>)</i>, 2016.
                [<a href="https://ieeexplore.ieee.org/document/7532885", target="_blank">Link</a>][<a href="./publications/ICIP2016AHMM/paper.pdf", target="_blank">PDF</a>][<a href="./publications/ICIP2016AHMM/bib.html", target="_blank">BibTeX</a>]</li>
        </ol>
    </p>
    <p class="textBlock">
        <b>Journal papers:</b>
        <ol>
            <li>Dan Guo, Hui Wang, and Meng Wang, "Context-Aware Graph Inference with Knowledge Distillation for Visual Dialog", <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</i>, 2021.[<a href="https://ieeexplore.ieee.org/document/9444809", target="_blank">Link</a>]</li>
            <li>Shengeng Tang, Dan Guo, Richang Hong, and Meng Wang, "Graph-Based Multimodal Sequential Embedding for Sign Language Translation", <i>IEEE Transactions on Multimedia (<strong>TMM</strong>)</i>, 2021.[<a href="https://ieeexplore.ieee.org/document/9556136", target="_blank">Link</a>][<a href="./publications/TMM2021MSeqGraph/paper.pdf", target="_blank">PDF</a>][<a href="./publications/TMM2021MSeqGraph/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Hui Wang, Shuhui Wang, and Meng Wang, "Textual-Visual Reference-Aware Attention Network for Visual Dialog", <i>IEEE Transactions on Image Processing (<strong>TIP</strong>)</i>, 2020.</li>
            <li>Dan Guo, Wengang Zhou, Anyang Li, Houqiang Li, and Meng Wang, "Hierarchical Recurrent Deep Fusion Using Adaptive Clip Summarization for Sign Language Translation", <i>IEEE Transactions on Image Processing (<strong>TIP</strong>)</i>, 2020.
                [<a href="https://ieeexplore.ieee.org/document/8846585", target="_blank">Link</a>][<a href="./publications/TIP2020HRF/paper.pdf", target="_blank">PDF</a>][<a href="./publications/TIP2020HRF/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Shuo Wang, Dan Guo, Xin Xu, Li Zhuo, and Meng Wang, "Cross-Modality Retrieval by Joint Correlation Learning", <i>ACM Transactions on Multimedia Computing Communications and Applications (<strong>TOMCCAP</strong>)</i>, 2019.
                [<a href="https://dl.acm.org/doi/10.1145/3314577", target="_blank">Link</a>][<a href="./publications/", target="_blank">PDF</a>][<a href="./publications/", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Wengang Zhou, Houqiang Li, and Meng Wang, "Online Early-Late Fusion Based on Adaptive HMM for Sign Language Recognition", <i>ACM Transactions on Multimedia Computing Communications and Applications (<strong>TOMCCAP</strong>)</i>, 2018.
                [<a href="https://dl.acm.org/doi/10.1145/3152121", target="_blank">Link</a>][<a href="./publications/TOMCCAP2018OELF/paper.pdf", target="_blank">PDF</a>][<a href="./publications/TOMCCAP2018OELF/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Dan Guo, Shengeng Tang, Richang Hong, and Meng Wang, "Review of Sign Language Recognition, Translation and Generation", <i>Computer Science</i>, 2021.[<a href="http://www.jsjkx.com/CN/10.11896/jsjkx.210100227", target="_blank">Link</a>][<a href="./publications/JSJKX2021Review/paper.pdf", target="_blank">PDF</a>][<a href="./publications/JSJKX2021Review/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Chengxin Xiong, Dan Guo, and Xueliang Liu, "Temporal Proposal Optimization for Temporal Action Detection", <i>Journal of Image and Graphics</i>, 2020.[<a href="http://www.cjig.cn/html/jig/2020/7/20200713.htm", target="_blank">Link</a>]</li>
            <li>Zhihong Lu, Dan Guo, and Meng Wang, "Motion-compensated Frame Interpolation Based on Weighted Motion Estimation and Vector Segmentation", <i>Acta Automatica Sinica</i>, 2015.[<a href="http://aas.net.cn/article/id/18677", target="_blank">Link</a>]</li>
        </ol>   
    </p>
    <p class="textBlock">
        <b>Patents:</b>
        <ol>
            <li>郭丹; 宋培培; 刘祥龙; 汪萌; 基于递归记忆网络的无监督图像描述模型的生成方法, 2022-3-15, 中国, ZL202010049142.2.</li>
            <li>郭丹; 宋培培; 刘祥龙; 汪萌; 基于数据自驱动的多阶特征动态融合手语翻译方法, 2022-3-15, 中国, ZL202010096391.7.</li>
            <li>郭丹; 王辉; 汪萌; 一种基于上下文感知图神经网络的视觉对话生成方法, 2021-6-8, 中国, ZL201910881298.4.</li>
            <li>郭丹; 李坤; 汪萌; 一种基于多尺度注意力机制的人群密度估计方法, 2021-3-9, 中国, ZL201910531606.0.</li>
            <li>郭丹; 王辉; 汪萌; 一种基于上下文感知图神经网络的视觉对话生成方法, 2021-6-8, 中国, ZL201910881298.4.</li>
            <li>郭丹; 宋培培; 赵烨; 汪萌; 基于自适应隐马尔可夫的多特征融合手语识别方法, 2020-07-10, 中国, ZL201811131806.9.</li>
            <li>郭丹; 汪萌; 周文罡; 李厚强; 李传青; 李安阳; 基于非对称多层LSTM的连续手语视频自动翻译方法, 2020-2-11, 中国, ZL201810027551.5.</li>
            <li>郭丹; 王硕; 汪萌; 基于时域卷积网络与循环神经网络融合的手语视频翻译方法, 2019-10-18, 中国, ZL201811070290.1.</li>
            <li>汪萌; 张鹿鸣; 郭丹; 一种基于多任务拓扑学习的航拍图像快速识别系统及其快速识别方法, 2018-2-6, 中国, ZL201510080478.4.</li>
            <li>汪萌; 张鹿鸣; 郭丹; 田绪婷; 一种基于几何重构和语义融合的视点追踪方法, 2017-10-3, 中国, ZL201410733763.7.</li>
            <li>郭丹; 胡学钢; 倪武; 吴信东; 一种基于最大流率路径优先的路网疏散规划方法, 2017-6-6, 中国, ZL201510451828.3.</li>
            <li>汪萌; 杨勋; 洪日昌; 郭丹; 刘奕群; 孙茂松; 一种基于语义映射空间构建的图像检索方法, 2017-5-17, 中国, ZL201410393094.3.</li>
            <li>汪萌; 洪日昌; 李炳南; 刘奕群; 郭丹; 刘学亮; 吴信东; 杨勋; 基于连续数标号子空间学习的检索重排序方法, 2017-2-22, 中国, ZL201410196946.X.</li>
            <li>汪萌; 张鹿鸣; 郭丹; 刘奕群; 孙茂松; 鲁志红; 基于GPS信息视频的三维场景重建方法, 2017-2-22, 中国, ZL201410752454.4.</li>
        </ol>   
    </p>


<h2 id="link">Link &nbsp<a href="#home" style="color:#666; font-size:15px;"></a></h2>
  <ul>
    <!--<li><a href="https://tangshengeng.github.io/CCF/" target="_blank">CCF Conferences</a>: Information Update of International Conferences Recommended by CCF.</li>
    -->
    <li><a href="https://blog.csdn.net/m0_37369043/article/details/102926076" target="_blank">Conferences Links</a>: International Conferences on Machine Learning and Artificial Intelligence.</li>
    <!-- <li><a href="./source/gpu_resources.html" target="_blank">GPU Resources</a>: Check GPU resources.</li> -->
  </ul>

<!-- <h2 align="center" style="border-bottom: none"><a href="../../index.html"><b>[Back to Homepage]</b></a></h2> -->
<hr style="height:1px;border:none;border-top:1px solid #555555;">
<div align="right" style="font-family:verdana;color:#800000">&copy; VUT-HFUT 2021 &nbsp&nbsp&nbsp&nbsp&nbsp Last updated on Apr. 23, 2022</div>

</body>
</html>
